{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Exercise\n",
    "In this exercise, we'll build a model that, as you'll see, dramatically overfits the training data. This will allow you to see what overfitting can \"look like\" in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use gradient boosted trees. In order to implement this model, we'll use the XGBoost package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/91/551d37ba472bcbd70a25e667acc65a18a9d053657b13afcf0f87aa24d7bb/xgboost-1.0.2-py3-none-manylinux1_x86_64.whl (109.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 109.8MB 353kB/s eta 0:00:010% |                                | 133kB 3.9MB/s eta 0:00:29    1% |▌                               | 1.8MB 15.6MB/s eta 0:00:07    3% |█                               | 3.5MB 19.9MB/s eta 0:00:06    10% |███▍                            | 11.8MB 27.8MB/s eta 0:00:04    14% |████▊                           | 16.3MB 33.0MB/s eta 0:00:03    16% |█████▏                          | 17.8MB 29.5MB/s eta 0:00:04    18% |██████                          | 20.7MB 31.3MB/s eta 0:00:03    25% |████████▏                       | 28.0MB 29.3MB/s eta 0:00:03    31% |██████████▏                     | 34.9MB 26.4MB/s eta 0:00:03    33% |██████████▋                     | 36.2MB 29.6MB/s eta 0:00:03    35% |███████████▍                    | 39.0MB 29.5MB/s eta 0:00:03    37% |████████████▏                   | 41.6MB 27.6MB/s eta 0:00:03    40% |█████████████                   | 44.3MB 27.8MB/s eta 0:00:03    41% |█████████████▎                  | 45.5MB 20.4MB/s eta 0:00:04    42% |█████████████▋                  | 46.7MB 25.0MB/s eta 0:00:03    43% |██████████████                  | 47.9MB 24.8MB/s eta 0:00:03    49% |███████████████▊                | 54.1MB 24.0MB/s eta 0:00:03    50% |████████████████▏               | 55.4MB 28.3MB/s eta 0:00:02    53% |█████████████████▎              | 59.2MB 27.3MB/s eta 0:00:02    57% |██████████████████▎             | 62.8MB 20.2MB/s eta 0:00:03    58% |██████████████████▊             | 64.1MB 20.6MB/s eta 0:00:03    61% |███████████████████▊            | 67.6MB 24.4MB/s eta 0:00:02    62% |████████████████████            | 68.9MB 26.1MB/s eta 0:00:02    64% |████████████████████▊           | 71.2MB 27.2MB/s eta 0:00:02    67% |█████████████████████▌          | 73.7MB 24.9MB/s eta 0:00:02    73% |███████████████████████▍        | 80.2MB 22.0MB/s eta 0:00:02    74% |███████████████████████▊        | 81.3MB 19.5MB/s eta 0:00:02    75% |████████████████████████▎       | 83.3MB 19.9MB/s eta 0:00:02    76% |████████████████████████▋       | 84.4MB 24.4MB/s eta 0:00:02    77% |█████████████████████████       | 85.4MB 22.4MB/s eta 0:00:02    78% |█████████████████████████▎      | 86.5MB 19.1MB/s eta 0:00:02    79% |█████████████████████████▌      | 87.6MB 21.9MB/s eta 0:00:02    83% |██████████████████████████▊     | 91.6MB 21.5MB/s eta 0:00:01    85% |███████████████████████████▎    | 93.7MB 24.2MB/s eta 0:00:01    89% |████████████████████████████▌   | 97.9MB 18.5MB/s eta 0:00:01    93% |██████████████████████████████  | 102.8MB 19.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from xgboost) (1.12.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from xgboost) (1.2.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a few helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows in a dataframe\n",
    "def nrow(df): \n",
    "    return(len(df.index))\n",
    "\n",
    "# number of columns in a dataframe\n",
    "def ncol(df): \n",
    "    return(len(df.columns))\n",
    "\n",
    "# flatten nested lists/arrays\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "# combine multiple arrays into a single list\n",
    "def c(*args):\n",
    "    return(flatten([item for item in args]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we're going to try to predict the returns of the S&P 500 ETF. This may be a futile endeavor, since many experts consider the S&P 500 to be essentially unpredictable, but it will serve well for the purpose of this exercise. The following cell loads the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SPYZ.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data file has four columns, `Date`, `Close`, `Volume` and `Return`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>146.8750</td>\n",
       "      <td>3172700</td>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>145.4375</td>\n",
       "      <td>8164300</td>\n",
       "      <td>-0.009787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>139.7500</td>\n",
       "      <td>8089800</td>\n",
       "      <td>-0.039106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>140.0000</td>\n",
       "      <td>12177900</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>137.7500</td>\n",
       "      <td>6227200</td>\n",
       "      <td>-0.016071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Close    Volume    Return\n",
       "0  1999-12-31  146.8750   3172700  0.001598\n",
       "1  2000-01-03  145.4375   8164300 -0.009787\n",
       "2  2000-01-04  139.7500   8089800 -0.039106\n",
       "3  2000-01-05  140.0000  12177900  0.001789\n",
       "4  2000-01-06  137.7500   6227200 -0.016071"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nrow(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll form our predictors/features. In the cells below, we create four types of features. We also use a parameter, `K`, to set the number of each type of feature to build. With a `K` of 25, 100 features will be created. This should already seem like a lot of features, and alert you to the potential that the model will be overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = []\n",
    "\n",
    "# we'll create a new DataFrame to hold the data that we'll use to train the model\n",
    "# we'll create it from the `Return` column in the original DataFrame, but rename that column `y`\n",
    "model_df = pd.DataFrame(data = df['Return']).rename(columns = {\"Return\" : \"y\"})\n",
    "\n",
    "# IMPORTANT: this sets how many of each of the following four predictors to create\n",
    "K = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you write the code to create the four types of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for L in range(1,K+1): \n",
    "    # this predictor is just the return L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `R1`, `R2`, etc.\n",
    "    pR = \"\".join([\"R\",str(L)]) \n",
    "    predictors.append(pR)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the return from L days before to the ith row of this predictor in `model_df`\n",
    "        model_df.loc[i, pR] = df.loc[i-L,'Return']\n",
    "\n",
    "    # this predictor is the return L days ago, squared, where L goes from 1 to K\n",
    "    # these predictors will be named `Rsq1`, `Rsq2`, etc.\n",
    "    pR2 = \"\".join([\"Rsq\",str(L)])\n",
    "    predictors.append(pR2)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the squared return from L days before to the ith row of this predictor \n",
    "        # in `model_df`\n",
    "        model_df.loc[i, pR2] = (df.loc[i-L,'Return']) ** 2\n",
    "\n",
    "    # this predictor is the log volume L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `V1`, `V2`, etc.\n",
    "    pV = \"\".join([\"V\",str(L)])\n",
    "    predictors.append(pV)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the log of the volume from L days before to the ith row of this predictor \n",
    "        # in `model_df`\n",
    "        # Add 1 to the volume before taking the log\n",
    "        model_df.loc[i, pV] = math.log(1.0 + df.loc[i-L,'Volume'])\n",
    "\n",
    "    # this predictor is the product of the return and the log volume from L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `RV1`, `RV2`, etc.\n",
    "    pRV = \"\".join([\"RV\",str(L)])\n",
    "    predictors.append(pRV)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the product of the return and the log volume from L days before to the\n",
    "        # ith row of this predictor in `model_df`\n",
    "        model_df.loc[i, pRV] = model_df.loc[i, pR] * model_df.loc[i, pV]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the predictors we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>R1</th>\n",
       "      <th>Rsq1</th>\n",
       "      <th>V1</th>\n",
       "      <th>RV1</th>\n",
       "      <th>R2</th>\n",
       "      <th>Rsq2</th>\n",
       "      <th>V2</th>\n",
       "      <th>RV2</th>\n",
       "      <th>R3</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>RV23</th>\n",
       "      <th>R24</th>\n",
       "      <th>Rsq24</th>\n",
       "      <th>V24</th>\n",
       "      <th>RV24</th>\n",
       "      <th>R25</th>\n",
       "      <th>Rsq25</th>\n",
       "      <th>V25</th>\n",
       "      <th>RV25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.016304</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>15.892349</td>\n",
       "      <td>-0.234024</td>\n",
       "      <td>-0.007529</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>16.198698</td>\n",
       "      <td>-0.121956</td>\n",
       "      <td>-0.018688</td>\n",
       "      <td>...</td>\n",
       "      <td>15.959991</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>15.695540</td>\n",
       "      <td>-0.145995</td>\n",
       "      <td>0.026421</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>16.209371</td>\n",
       "      <td>0.428273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>16.221058</td>\n",
       "      <td>0.264474</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>15.892349</td>\n",
       "      <td>-0.234024</td>\n",
       "      <td>-0.007529</td>\n",
       "      <td>...</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>15.959991</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>15.695540</td>\n",
       "      <td>-0.145995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>15.929221</td>\n",
       "      <td>-0.273290</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>16.221058</td>\n",
       "      <td>0.264474</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>...</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "      <td>-0.010865</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>15.959991</td>\n",
       "      <td>0.076664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>15.387039</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>15.929221</td>\n",
       "      <td>-0.273290</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>...</td>\n",
       "      <td>15.858172</td>\n",
       "      <td>-0.178954</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "      <td>-0.010865</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>15.494960</td>\n",
       "      <td>0.529838</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>15.387039</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>...</td>\n",
       "      <td>16.562480</td>\n",
       "      <td>-0.054770</td>\n",
       "      <td>-0.011285</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>15.858172</td>\n",
       "      <td>-0.178954</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y        R1      Rsq1         V1       RV1        R2      Rsq2  \\\n",
       "100  0.016304 -0.014726  0.000217  15.892349 -0.234024 -0.007529  0.000057   \n",
       "101 -0.017157  0.016304  0.000266  16.221058  0.264474 -0.014726  0.000217   \n",
       "102  0.001133 -0.017157  0.000294  15.929221 -0.273290  0.016304  0.000266   \n",
       "103  0.034194  0.001133  0.000001  15.387039  0.017437 -0.017157  0.000294   \n",
       "104  0.000657  0.034194  0.001169  15.494960  0.529838  0.001133  0.000001   \n",
       "\n",
       "            V2       RV2        R3    ...           V23      RV23       R24  \\\n",
       "100  16.198698 -0.121956 -0.018688    ...     15.959991  0.076664 -0.009302   \n",
       "101  15.892349 -0.234024 -0.007529    ...     16.372203 -0.177882  0.004804   \n",
       "102  16.221058  0.264474 -0.014726    ...     16.461827  0.683503 -0.010865   \n",
       "103  15.929221 -0.273290  0.016304    ...     15.858172 -0.178954  0.041520   \n",
       "104  15.387039  0.017437 -0.017157    ...     16.562480 -0.054770 -0.011285   \n",
       "\n",
       "        Rsq24        V24      RV24       R25     Rsq25        V25      RV25  \n",
       "100  0.000087  15.695540 -0.145995  0.026421  0.000698  16.209371  0.428273  \n",
       "101  0.000023  15.959991  0.076664 -0.009302  0.000087  15.695540 -0.145995  \n",
       "102  0.000118  16.372203 -0.177882  0.004804  0.000023  15.959991  0.076664  \n",
       "103  0.001724  16.461827  0.683503 -0.010865  0.000118  16.372203 -0.177882  \n",
       "104  0.000127  15.858172 -0.178954  0.041520  0.001724  16.461827  0.683503  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.iloc[100:105,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a DataFrame that holds the recent volatility of the ETF's returns, as measured by the standard deviation of a sliding window of the past 20 days' returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df = pd.DataFrame(data = df[['Return']])\n",
    "\n",
    "for i in range(K+1,n): \n",
    "    # TODO: create the code to assign the standard deviation of the return from the time period starting \n",
    "    # 20 days before day i, up to the day before day i, to the ith row of `vol_df`\n",
    "    vol_df.loc[i, 'vol'] = np.std(vol_df.loc[(i-20):(i-1),'Return'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Return</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.013069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.013615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.014007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.014008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.015792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Return       vol\n",
       "100  0.016304  0.013069\n",
       "101 -0.017157  0.013615\n",
       "102  0.001133  0.014007\n",
       "103  0.034194  0.014008\n",
       "104  0.000657  0.015792"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_df.iloc[100:105,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we can start thinking about training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training, we'll use all the data except for the first K days, for which the predictors' values are NaNs\n",
    "model = model_df.iloc[K:n,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, first split the data into train and test sets, and then split off the targets from the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_size = 2.0/3.0\n",
    "breakpoint = round(nrow(model) * train_size)\n",
    "\n",
    "# TODO: fill in the code to split off the chunk of data up to the breakpoint as the training set, and\n",
    "# assign the rest as the test set.\n",
    "training_data = model.iloc[1:breakpoint,:]\n",
    "test_data = model.loc[breakpoint : nrow(model),]\n",
    "\n",
    "# TODO: Split training data and test data into targets (Y) and predictors (X), for the training set and the test set\n",
    "X_train = training_data.iloc[:,1:ncol(training_data)]\n",
    "Y_train = training_data.iloc[:,0]\n",
    "X_test = test_data.iloc[:,1:ncol(training_data)]\n",
    "Y_test = test_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that we have our data, let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMatrix is a internal data structure that used by XGBoost which is optimized for both memory efficiency \n",
    "# and training speed. \n",
    "dtrain = xgb.DMatrix(X_train, Y_train)\n",
    "\n",
    "# Train the XGBoost model\n",
    "param = { 'max_depth':20, 'silent':1 }\n",
    "num_round = 20\n",
    "xgModel = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict the returns for the S&P 500 ETF in both the train and test periods. If the model is successful, what should the train and test accuracies look like? What would be a key sign that the model has overfit the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: Before you run the next cell, write down what you expect to see if the model is overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions on the test data\n",
    "preds_train = xgModel.predict(xgb.DMatrix(X_train))\n",
    "preds_test = xgModel.predict(xgb.DMatrix(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look at the mean squared error of the predictions on the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6237099209080407e-06"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate the mean squared error on the training set\n",
    "msetrain = sum((preds_train-Y_train)**2)/len(preds_train)\n",
    "msetrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.711855498216044e-05"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculate the mean squared error on the test set\n",
    "msetest = sum((preds_test-Y_test)**2)/len(preds_test)\n",
    "msetest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the mean squared error on the test set is an order of magnitude greater than on the training set. Not a good sign. Now let's do some quick calculations to gauge how this would translate into performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAD8CAYAAABU4IIeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8VNX5x/HPkx0IEJaASEAWEUQQhAhYrfuC2IpLqdiqaFXq9mut/WnV2p/7Vq1WbdVSRbFVRAUVFUXc6lZk3xcJCBIIhDUsIfvz+2MubcQQhjCTmSTf9+s1r7n3zL13njNZnjn3nHuPuTsiIiKRkhDrAEREpH5RYhERkYhSYhERkYhSYhERkYhSYhERkYhSYhERkYhSYhERkYhSYhERkYhSYhERkYhKinUA0dC6dWvv1KlTrMMQqZ+WLg09d+8e2zgk4mbOnLnR3TMP9Dj1MrF06tSJGTNmxDoMkfrpxBNDz598EssoJArMbFUkjqNTYSIiElFKLCIiElFKLCIiElFKLCIiElFKLCIiElFKLCIiElFKLCIiElH18joWEWlYysoreHVmLhu2F9MoOZGWTVLo2KoxGY2SWVtQRNtmqZSWOeXuNE1LIiUxgYzGyaSnJmFmLF23naLSckrKKzAgOTGBzplNaJycSGFpOXNXb2VXSTmJCUaCGb3aNyezaWqsqx23lFhEpE7aWljCZ8s24sCTH+ewZN32/T5GalICxWUVNY7htJ5tyd9WxNzcAjKbplKwq5RmackkGBSVlpPROIWOLRszqEtLOrdOZ/6aApqmJVFYUkZ6ajIHNU+lc+t0+mQ1x8y+d/xVm3ayvaiM3C2F5G8vpmWTFNKSEklLTqRT68ZUVEBxWSjhFZaUs6O4jMYpiRyZlVHjOkWCEouIREx5hfNFzkbeXZBHXkER6wqK6N2+OQW7Sikuq8CBlMQECnaVsHlnCY1TkiivcIrLylm+YSctm6SQnppE80bJLF2/na6Z6ewqKaO03Mlq0Yi05ES27iolNTGBaSs3f+/9l9w9mNLyCtZvK2bt1l1sKSyhSUoShaXlpCUlkGDG5sIS8rcVkZyYwKK8bbw5Zy292jfj16ccRlpyAu6wblsRa7fuIid/B10y0+nboTmZ6Wk4ztl/+eI/7zd1+Sa2F5cBcMTBzfh2UyHpaUl0atWEWd9u4ZBWjVmxYSef52ys9nNrmpZE7/bNaZySiDvsLCljZ3E5C9YW4L5/P4O+HTJ449pj92+nCFNiEZEacXfueWcxb8xeQ2FJ6DRSecV//wumJSdQVFrBlsISMhqlkJqcQElZBUvWbeegZmn06dCcLYWlNE1NIjU5gbbN0shsmkqFw7qCXVRUOE1Tk+ia2YSZq7bw1TebaZqWRJfWTUhIgPYZjfjZwI6ccURbCnaV0at9M1KDb/NN05I5tE16WPV4bPhR+1XvJXcP5sPF+QzpfVCVrYyq7Cwu45uNO9lSWMJRHVuwvaiUJqlJPPXJckZ9uoKe7ZqxvaiMtVt3kWBGq/QUMhonc0F2BwZ0bknBrlJKyio4pmsrAAp2lbI8fwfJSQk0TkkkwYzkxNBy6/TYn6Iz3990GO6BzdKAT4FUQgnsNXe/3cyeB04ACoJNL3X3ORb6CT0GDAEKg/JZwbFGALcF29/j7mOqe+/s7GzXvcJEouTEE9leVMZJP7qdjTtKaJ/RiCG9DyIlKYGUxESapiVxXr/2ZDROqXL37UWl/+nbqE5FhZOQEN4/bokMM5vp7tkHepxotliKgZPdfYeZJQOfm9m7wWs3uvtre2x/JtAteAwEngIGmllL4HYgG3BgpplNdPctUYxdRPbCgS2FJWzcUcJtZx3OsOwONG+UHPb+TdPC21ZJpe6KWmLxUFNoR7CaHDyqax4NBV4I9ptqZhlm1g44EZji7psBzGwKMBgYG63YRaRq+duLyMsNjZDKaJzMFT/sEuuQJA5F9ToWM0s0szlAPqHk8FXw0r1mNs/MHjWz3ScE2wOrK+2eG5TtrVxEaom788xnK/jhgx+zq6ScrBaNeeu642IdlsSpqCYWdy93975AFjDAzHoBtwA9gKOBlsDvgs2ravd6NeXfYWYjzWyGmc3YsGFDROIXkZCx01ZzzzuLObRNOr2zMshq0YgOLRvHOiyJU7Vy5b27bwU+AQa7e56HFAPPAQOCzXKBDpV2ywLWVlO+53uMcvdsd8/OzDzgCdBEJLBk3TZufX0+/Tpm8Po1x9IkJTHWIUmci1piMbNMM8sIlhsBpwJLgn4TglFg5wALgl0mApdYyCCgwN3zgMnA6WbWwsxaAKcHZSISZU99spyz//IFZvDA+UeSkqS7QMm+RXNUWDtgjJklEkpgr7j722b2kZllEjrFNQe4Kth+EqGhxjmEhhtfBuDum83sbmB6sN1duzvyRSQ63J1/TF3Fg+8toXf75vx5eF+6ZoZ3XYhINEeFzQO+d+WRu5+8l+0duHYvr40GRkc0QBHZq7HTVvN/by5kQKeWjLqk/16vSRGpiq68F5HveG1mLre+Pp8OLRsxduQgEnU9iewnJRYRAWDGys28MWcNr83MpV/HDB4bfpSSitSIEotIA1dYUsaD7y5hzL9XkZKYwEk9Mrl7aC/aNEuLdWhSRymxiDRgWwtLuOBvU1m6fjsXDerITYN70CzMW66I7I0Si0gDtWjtNi4fM51124p46CdHMiy7w753EgmDEotIA7OrpJzXZq7msQ+XkZyYwGtX/YD+h7SIdVhSjyixiDQw/zN2Nh8sXq/rUyRqlFhEGpgFawoY0vsgnvx5/1iHIvWU7s8g0oBUVDgbdxRzSKsmsQ5F6jElFpEGZMaqLZRVOJ2VWCSKlFhEGogl67ZxzYuzABjUpVWMo5H6TIlFpAGYsXIzF/xtKuC8dOVAOrbSXCoSPeq8F6nnthWV8st/zKRZoyReumKQJuiSqFOLRaQe+3ZTIef+9Qu27irlvnN7K6lIrVCLRaSe+tfXG7h1wny2FJYw5rIBHNetdaxDkgZCiUWkHhrz5Upun7iQpATjvvN6K6lIrVJiEalHKiqcF/69kjveWsTxh2Uy6uL+pCVrjnqpXepjEalHPvk6nzveWkTLJik8+tM+SioSE1FLLGaWZmbTzGyumS00szuD8s5m9pWZLTOzcWaWEpSnBus5weudKh3rlqB8qZmdEa2YReqyotJy7nprEQAf3nACrdJTYxyRNFTRbLEUAye7ex+gLzDYzAYBDwKPuns3YAtwebD95cAWdz8UeDTYDjPrCQwHjgAGA0+amb6GiVTy909X0OfO91m5qZAHzutNiyaao15iJ2qJxUN2BKvJwcOBk4HXgvIxwDnB8tBgneD1U8zMgvKX3b3Y3b8BcoAB0YpbpK6ZvHAd905aTOv0VG4+swfDB3SMdUjSwEW18z5oWcwEDgX+CiwHtrp7WbBJLtA+WG4PrAZw9zIzKwBaBeVTKx228j4iDdqmHcVc++IsDm6expQbjqdxisbjSOxFtfPe3cvdvS+QRaiVcXhVmwXPtpfX9lb+HWY20sxmmNmMDRs21DRkkTpjwqxcjn3wI8oqnJsG91BSkbhRK6PC3H0r8AkwCMgws91/AVnA2mA5F+gAELzeHNhcubyKfSq/xyh3z3b37MzMzGhUQyRu/P71+dzwylwapyTx90uyGdr34FiHJPIf0RwVlmlmGcFyI+BUYDHwMfCTYLMRwJvB8sRgneD1j9zdg/LhwaixzkA3YFq04haJZ0Wl5dz46lxe/OpbhvY9mM9uOonTerYl1B0pEh+i2XZuB4wJ+lkSgFfc/W0zWwS8bGb3ALOBZ4PtnwX+YWY5hFoqwwHcfaGZvQIsAsqAa929PIpxi8SlJeu2MWL0NNZvK+b8flk8cH5vkhN1KZrEn6glFnefBxxVRfkKqhjV5e5FwLC9HOte4N5IxyhSF7g7f/5gGU/9aznlFc6zI7I5uUcbtVIkbqm3TySOuTu3TJjPy9NX88NurblraC86t9bsjxLflFhE4tjyDTt4efpqTu7RhmdHZKuVInWCTtCKxLH3F60H4K6hRyipSJ2xz8RiZm3N7FkzezdY72lml+9rPxE5MKXlFYz5ciXd2zYlq4Um6JK6I5wWy/PAZGD3QPmvgeujFZCIQFl5BfdPWsL6bcX84rhOsQ5HZL+E08fS2t1fMbNb4D+3W9FwX5EocHde/Opbxny5kmX5OzjvqPb8pH+Hfe8oEkfCSSw7zawVwW1UgjsUF0Q1KpEGatz01dz2xgK6tUnnwfN7c8HRuqGk1D3hJJYbCF393tXMvgAy+e+V8yISIUWl5Twy5WuOzGrOG9ccS0KCOuulbtpnYnH3WWZ2AtCd0A0hl7p7adQjE2lANu0o5vpxc8jfXsx95/ZWUpE6bZ+JxcyuBV5094XBegszu9Ddn4x6dCL13K6Scm4aP4935+dRVuFckN2BU3u2jXVYIgcknFNhV7r7X3evuPsWM7sSUGIROQBFpeXc+dZC3pq7losGdeTiQZ3oflDTWIclcsDCSSwJZmbBnYZ3T96leU9FDkBRaTmXj5nOFzmbuOSYQ7hraK9YhyQSMeEklsnAK2b2NKGRYVcB70U1KpF6bM7qrVwxZjobd5Rw4xndufakQ2MdkkhEhZNYfgf8EriaUOf9+8Az0QxKpL76cvlGrnlxFqVlFTx/2dGc2L1NrEMSibhwRoVVAE8FDxGpoUfeX8rjH+VwcPM0Hr8km+xOLWMdkkhUhDMq7FjgDuCQYHsD3N27RDc0kfqhoLCUB95bwthp33JkVnPGjTyGRimJsQ5LJGrCORX2LPAbYCagW7mI7IcZKzfz65fnsG5bEWf3OZj7z+utpCL1XjiJpcDd3416JCL1yJadJfz21bl8tCSfVk1SeOEXAzj20NaxDkukVoSTWD42s4eACUDx7kJ3nxW1qETqsPIK56Jnv2Lh2m1cdUJXfnl8F1o00Qh9aTjCSSwDg+fsSmUOnFzdTmbWAXgBOAioAEa5+2NmdgdwJbAh2PRWd58U7HMLcDmhU26/cvfJQflg4DEgEXjG3R8II26RWlde4dwxcSEL127jtrMO54ofqitSGp5wRoWdVMNjlwG/De411hSYaWZTgtcedfeHK29sZj2B4cARhOZ++cDMDgte/itwGpALTDezie6+qIZxiUSFuzN81L+ZvnILQ/sezOXHdY51SCIxEdac92Z2FqF/+Gm7y9z9rur2cfc8IC9Y3m5mi4H21ewyFHjZ3YuBb8wsBxgQvJbj7iuCWF4OtlVikbiRv72ICbPWMH3lFs7pezCPXtBXUwlLgxXO1MRPAxcA/0NoqPEwQkOPw2ZmnYCjgK+CouvMbJ6ZjTazFkFZe2B1pd1yg7K9le/5HiPNbIaZzdiwYcOeL4tEzQeL1nP8Hz/mgXeXcGRWc+44W/PTS8MWztTEP3D3S4At7n4ncAwQ9pR2ZpYOjAeud/dthC607Ar0JdSi+dPuTavY3asp/26B+yh3z3b37MzMzHDDE6mx0vIKfv3ybK54YQZdM9MZf/UxTLj6B2Q0Vke9NGzhnArbFTwXmtnBwCYgrJPHZpZMKKm86O4TANx9faXX/w68Hazm8t2ElQWsDZb3Vi4SM5MXruPNOaE7E9865HAap4R1Zlmk3gunxfK2mWUADwGzgJXAy/vayULnAp4FFrv7I5XK21Xa7FxgQbA8ERhuZqlm1hnoBkwDpgPdzKyzmaUQ6uCfGEbcIlH10ZJ8khKM287qqaQiUkk4o8LuDhbHm9nbQJq7hzPn/bHAxcB8M5sTlN0KXGhmfQmdzlpJ6AaXuPtCM3uFUKd8GXCtu5cDmNl1hO6ynAiM3j3pmEis5OTvYMKsNVz6g06kJetKepHKwrlXWCJwFtBp9/ZmRuVWSFXc/XOq7h+ZVM0+9wL3VlE+qbr9RGrb0/9aDsBFg/ZrHItIgxBO+/0toAiYT+hCR5EGLXdLIa/PXsMpPdpwaJv0WIcjEnfCSSxZ7n5k1CMRqQPeW5DHTa/NI9GMa0/WBF0iVQmn8/5dMzs96pGIxLkvczZy1T9ncUirJrx7/Q/p17HFvncSaYDCabFMBV43swSglP/Ox9IsqpGJxJEPFq3nmhdn0aZpKs9fdjSt0lNjHZJI3AonsfyJ0EWR8939excmitR3+duKGPmPGTRvlMxLVw5SUhHZh3BOhS0DFiipSEP05fKNnP/0lzjwzIij1VkvEoZwWix5wCdm9i7fnY+l2uHGInXZsvXb+d/X5jF39VaapiYx6uJs+h+iPhWRcISTWL4JHinBQ6Tee2TK18xdvZXLj+vMVSd0JbOpTn+JhKvaxBJcHJnu7jfWUjwiMZe7pZB3F6zjF8d25g8/6hnrcETqnGoTi7uXm1m/2gpGJNae+WwFD7+/lKQE46dHZ8U6HJE6KZxTYXPMbCLwKrBzd+HuuxWL1Bezv93CPe8s5sTumfz2tO70OEgj6kVqIpzE0pLQrfIrz3HvgBKL1Aul5RWM/vwbHv9wGW2bpfL4hUfRLC051mGJ1Fnh3N34stoIRCQW3J3rx83hnXl5HNUxg7vO7qWkInKAwpmaOMvMXjezfDNbb2bjzUwnn6VemLxwHe/My+PqE7sy4eof0DureaxDEqnzwrlA8jlCE2sdTGiu+beCMpE6bfPOEm58dR7tMxpx/andNE+9SISEk1gy3f05dy8LHs8DmlRe6rQ3Zq/h1Ef+xfbiMu45txepSZqsSyRSwkksG83sIjNLDB4XEerMF6lzthaWcM2LM7l+3BwSE4zHhvflpO5tYh2WSL0SzqiwXwB/AR4lNBrsy6BMpM754+SlTJq/jl+e0IVrTjyU5o3UUS8SaXttsZjZg8HiQHc/290z3b2Nu5/j7qv2dWAz62BmH5vZYjNbaGa/DspbmtkUM1sWPLcIys3MHjezHDObV/nCTDMbEWy/zMxGHGCdpYHKyd/OS199y/n9srjlzMOVVESipLpTYUPMLBm4pYbHLgN+6+6HA4OAa82sJ3Az8KG7dwM+DNYBzgS6BY+RwFMQSkTA7cBAYABw++5kJBKuKYvW86MnPiclMYErj+8c63BE6rXqEst7wEbgSDPbZmbbKz/v68Dunufus4Ll7cBiQqPKhgJjgs3GAOcEy0OBFzxkKpBhZu2AM4Ap7r7Z3bcAU4DB+19VaajWbyvimhdnktWiMROu+YGuqBeJsr0mFne/0d2bA++4ezN3b1r5eX/exMw6AUcBXwFt3T0veI88YHfPaXtgdaXdcoOyvZWL7NOmHcVc+tx0Ssudx4b3pVd7XaciEm3h3N24yYG8gZmlA+OB6919WzXXClT1gldTvuf7jCR0Co2OHTvWLFipV5at384vxkxnzZZd3H9eb444WElFpDaEc3fjQjNr7u4F+3vwoI9mPPBipZtWrjezdu6eF5zqyg/Kc4EOlXbPAtYG5SfuUf5JFbGOAkYBZGdna7bLBiyvYBe3vb6AD5fkk2Dwwi8Gcly31rEOS6TBCGe4cREw38ym8N27G/+qup0s1DR5Fli8x2yTE4ERwAPB85uVyq8zs5cJddQXBMlnMnBfpQ7706n5gAJpAB6avJQPl+Tzq1O6cXafgzWdsEgtCyexvBM89texwMWEktKcoOxWQgnlFTO7HPgWGBa8NgkYAuQAhcBlAO6+2czuBqYH293l7ptrEI80EFt2ltC7fXNuOO2wWIci0iCFc3fjMWbWCOjo7kvDPbC7f07V/SMAp1SxvQPX7uVYo4HR4b63NGzFZRWkJYdzUwkRiYZw7m78Y2AOoeHHmFnfYOIvkbi0o7iMlCQlFpFYCeev7w5CFyZuBXD3OYCuMJO49M+pq5iXW0DjlHDO8opINITz11fm7gV7DBPWqCuJKyVlFYz6dDkPv/81h7VN58Yzusc6JJEGK5zEssDMfgYkmlk34FeEbkQpEhcWri3gupdm883GnZxwWCZP/ExTC4vEUjiJ5X+A3wPFwEvAZOCeaAYlEq7tRaVcMWYGeQVFjL40m5O6t9GEXSIxtq8r7zOBQ4CH3P33tROSSHh2lZTzu/HzyCso4vdDDufkHm1jHZKIUE1iMbMrgPuA5UBnMxvp7hoNJnFh045ijnvwY3aVlvOzgR258vgusQ5JRALVtViuB45w9w1m1gV4kdDV8SIx9enXG7jhlTmUlFdw37m9uXBAh33vJCK1prrEUuLuGwDcfYWZpdZSTCJV+vfyTfzvq3NZs3UXGY2TeWZEtqYVFolD1SWWLDN7fG/r+7pXmEikuDt//mAZT3y0jEbJidz+454MP7ojjVISYx2aiFShusRy4x7rM6MZiMje3P/uEkZ9uoLsQ1rw6AV96dCycaxDEpFq7DWxuPuYvb0mUlv+9fUGRn26gvP6teeP5x9JUqJu1SIS7/RXKnFr0vw8rhwzg6ZpSdw1tJeSikgdoRsqSVwaN/1bfjd+PgCvXnUM6an6VRWpK/TXKnFl7dZd3PvOYt6Zn0ePg5py59lH0KdDRqzDEpH9UN0Fkk9Qzc0mNSpMIu3NOWu4dcJ8KhyuPakr1596GMk6/SVS51TXYpkRPB8L9ATGBevD0AgxibDVmwv5zbg5VDi8/5vjOaxt01iHJCI1tM9RYWZ2KXCSu5cG608D79dKdNIgrNq0k8uen44D468+RklFpI4L5zzDwUDlv/T0oKxaZjbazPLNbEGlsjvMbI2ZzQkeQyq9douZ5ZjZUjM7o1L54KAsx8xuDq9aUhcUlZZzw7g5nPnYZ6zYsJMnf9aP/oe0jHVYInKAwum8fwCYbWYfB+snEJpVcl+eB/4CvLBH+aPu/nDlAjPrCQwHjiCUtD4ws8OCl/8KnAbkAtPNbKK7Lwrj/SXOjZu+mgmz13B6z7b89vTudD9ILRWR+mCficXdnzOzd4GBQdHN7r4ujP0+NbNOYcYxFHjZ3YuBb8wsh9B0yAA57r4CwMxeDrZVYqnD3J235uVxzzuL6Nshg79d3F9zqIjUI/s8FWahv/hTgT7u/iaQYmYD9rFbda4zs3nBqbIWQVl7YHWlbXKDsr2VSx1VXuH89pW5/GrsbA5p1YQnLjxKSUWkngmnj+VJ4BjgwmB9O6HTUzXxFNAV6AvkAX8Kyqv6z+LVlH+PmY00sxlmNmPDhg01DE+iqbCkjNveWMCE2Ws476j2TL7+eN33S6QeCqePZaC79zOz2QDuvsXMUmryZu6+fveymf0deDtYzQUqT6qRBawNlvdWvuexRwGjALKzs/d6/Y3ExsYdxfz4ic/JKyji/H5ZPDzsSLVUROqpcBJLqZklErQUgumKK2ryZmbWzt3zgtVzgd0jxiYCL5nZI4Q677sB0wi1WLqZWWdgDaEO/p/V5L0ldgp2lXLxs9PIKyjiyZ/3Y0jvdrEOSUSiKJzE8jjwOtDGzO4FfgL8YV87mdlY4ESgtZnlArcDJ5pZX0JJaiXwSwB3X2hmrxDqlC8DrnX38uA41wGTgURgtLsv3J8KSuwUlZZz36TFvDojl12l5Rx7aCslFZEGIJxRYS+a2UzgFEItiHPcfXEY+11YRfGz1Wx/L3BvFeWTgEn7ej+JP09+nMML/17FsP5ZnN8/i34dW+x7JxGp8/aZWMzsH+5+MbCkijKR7ykrr+CJj3J4/KMchvQ+iIeG9Yl1SCJSi8I5FXZE5ZWgv6V/dMKRus7duez56Xy2bCMnds/k/vOOjHVIIlLLqru78S3ArUAjM9vGf4f+lhCMvhKprLCkjIcnf81nyzZy5Q87c+uQwzXyS6QBqu4mlPcD95vZ/e5+Sy3GJHVQUWk5lz43nWnfbOZHR7bjN6cdpqQi0kCF03l/S3CFfDcgrVL5p9EMTOqO5Rt2cPEzX7G2oIhbh/Rg5PFdYx2SiMRQOJ33VwC/JnRx4hxgEPBv4OTohibxzt159INlPPHRMhLM+NOwPpzfPyvWYYlIjIXTef9r4GhgqrufZGY9gDujG5bEu4oK5/dvzGfstNWc3KMNt511OF0y02MdlojEgXASS5G7F5kZZpbq7kvMrHvUI5O49tD7Sxk7bTU/G9iRe8/ppf4UEfmPcBJLrpllAG8AU8xsC3u5X5fUf/NzC3jgvcV8kbOJH3ZrraQiIt8TTuf9ucHiHcFkX82B96IalcSlnPwd/OTpL2malsTNZ/bg0h90UlIRke+p7jqWquaInR88pwOboxKRxKWSsgrueWcRpeUVPDPiaPp2yIh1SCISp6prscyk+jlRukQlIok7077ZzP++OpdvNxdy9YldlVREpFrVXSDZuTYDkfjj7vzhzQX8c+q3HNQsjecvO5oTDsuMdVgiEufCuY7l+KrKdYFk/ZZXsIuH3lvKhNlrOL9fFr8/63BaNqnR/G4i0sCEMyrsxkrLacAAQqfJdIFkPbVxRzFn/+ULNmwv5uJBh3DX0CPUSS8iYQtnVNiPK6+bWQfgj1GLSGLuuS++YcP2YsZeOYhjuraKdTgiUseE02LZUy7QK9KBSOwVlZbzhzcW8OrMXAZ2bqmkIiI1Ek4fyxME890DCUBfYG40g5La5+7cPH4eb8xZy0+zs/jd4B6xDklE6qhwWiwzKi2XAWPd/YsoxSMxUFxWzi//MZNPlm7gZwM7ct+5vWMdkojUYeH0sYypyYHNbDTwIyDf3XsFZS2BcUAnYCXwU3ffYqGe4ceAIUAhcKm7zwr2GQHcFhz2nprGI1UrKCzlJ09/ybL8HQzrn8W95+gsp4gcmIR9bWBmPzKz2Wa22cy2mdn2YEbJfXkeGLxH2c3Ah+7eDfgwWAc4k9B8L92AkcBTwXu3BG4HBhIajXZ7MDeMHKCy8gremL2Gc578ghUbd/L0Rf14aFgfjf4SkQO2z8QC/BkYAbRy92bu3tTdm+1rp+A6lz1v+zIU2N3iGAOcU6n8BQ+ZCmSYWTvgDGCKu2929y3AFL6frKQG/vDmQq4fN4fi0nJGXdyfwb3axTokEaknwuljWQ0scHff55b71tbd8wDcPc/M2gTl7YP32S03KNtb+feY2UhCrR06duwYgVDrr0+W5jN22rcM7XswDw/rQ3JiON8vRETCE05iuQmYZGb/Aop3F7r7IxGMY2/3I9tb+fcL3UcBowCys7MjkQTrnc07S7hlwjxgzLjLAAANdUlEQVQ+WJxP18wm3DW0l5KKiERcOInlXmAHoavuD/SeHuvNrF3QWmkH5AfluUCHSttlEZrzJRc4cY/yTw4whgZpwZoCLnt+Opt2FHPB0R351SmH0rxRcqzDEpF6KJzE0tLdT4/Q+00k1F/zQPD8ZqXy68zsZUId9QVB8pkM3Fepw/504JYIxdJgTF+5meGjptKmaSpvXHssR2bp7sQiEj3hJJYPzOx0d39/fw5sZmMJtTZam1kuodFdDwCvmNnlwLfAsGDzSYSGGucQGm58GYC7bzazu4HpwXZ3ubvmgQlTRYUzbsZq7nxrIRmNkhk38hg6tmoc67BEpJ4LJ7FcC9xkZsVAKaF+D9/XyDB3v3AvL51SxbYevE9VxxkNjA4jTqlkwZoC7nprEdNWbua4Q1vz5+F9aZ2eGuuwRKQBCOcCyaa1EYhEzpzVWzn3yS9IT0nigfN689PsDiQk6PoUEakd1U1N3MPdl5hZv6pe331lvMSXnPwdXPfSLDLTU5l43XEc1Dwt1iGJSANTXYvlBkLXhfypitcczccSd6av3Mylo6eRlJjA6EuPVlIRkZiobmrikcHzSbUXjtSEu/PkJ8t5+P2ltGuWxguXD+DQNjqDKSKxUd2psKOB1e6+Lli/BDgfWAXcodFZ8aGiwrl5wjxemZFL9iEteOqi/mQ2VSe9iMROdZdd/w0ogf/Me/8A8AJQQHCFu8TWqzNWM/SvX/DKjFzOO6o9L105SElFRGKuuj6WxEqtkguAUe4+HhhvZnOiH5pU59/LN3Hja/No1zyNe87pxc8HdtSdiUUkLlSbWMwsyd3LCF17MjLM/STKSsoqeGTKUto1T+PD355A4xT9OEQkflT3H2ks8C8z2wjsAj4DMLNDCZ0Ok1rm7ry7YB0PT17Kio07uXvoEUoqIhJ3qhsVdq+ZfQi0A96vdNv8BOB/aiM4+a4X/r2K2ycupEvrJoy6uD+nH3FQrEMSEfmear/uBpNu7Vn2dfTCkb1Zv62Ih99fyoDOLRl75SASdSW9iMQpTcZRB7g7D763hO1FZdw65HAlFRGJa0osdcA/pq5iwqw1XH5cZ/p20C3vRSS+qec3jrk7V/1zJpMXrqd726b8bnCPWIckIrJParHEsTFfrmTywvUM65/F+Gt+QEqSflwiEv/UYolTy9Zv5463FtGrfTPuPqcXacmJsQ5JRCQsSixx6N35eTz+UQ4Ajw8/SklFROoUJZY44u7c885inv38G5qkJHLjGd3pkpke67BERPZLTBKLma0EtgPlQJm7Z5tZS2Ac0AlYCfzU3bdY6AZYjwFDgELg0vo6ydhzX6zk2c+/4dyj2vPg+UeqT0VE6qRY/uc6yd37unt2sH4z8KG7dwM+DNYBzgS6BY+RwFO1HmmUuTufLdvAfZMWk5acwCM/7aOkIiJ1Vjz99xoKjAmWxwDnVCp/wUOmAhlm1i4WAUaDu3Pz+Plc/Ow0Mhqn8PdLsnWXYhGp02LVx+LA+2bmwN/cfRTQ1t3zANw9z8zaBNu2B1ZX2jc3KMurzYCjYc3WXVz9z5nMyy1gWP8s7hrai0Yp6qgXkbotVonlWHdfGySPKWa2pJptq/r67t/byGwkwa39O3bsGJkoo8Tdef7LlfztXyvYtLOYu4cewUWDDlFLRUTqhZicCnP3tcFzPvA6MABYv/sUV/CcH2yeC3SotHsWsLaKY45y92x3z87MzIxm+Afsq282c+dbi2jbPI1nRhzNxcd0UlIRkXqj1hOLmTUxs6a7l4HTgQXARGBEsNkI4M1geSJwiYUMAgp2nzKrq/45dRUpiQm8dMVATjgsvpOgiMj+isWpsLbA68E39CTgJXd/z8ymA6+Y2eXAt8CwYPtJhIYa5xAabnxZ7YccOe8tyOPteXmc1bsdTVJ1GZGI1D+1/p/N3VcAfaoo30RoCuQ9yx24thZCiyp3539fncf4Wbm0aZrKfef2jnVIIiJRoa/MtWB3Z/34WblcPOgQfnPaYTRvnBzrsEREokKJJco27yzh9okLeWvuWvpkNef/ftyT5MR4unxIRCSylFiipLCkjDsnLuLVmasxM646oSs3nHaYkoqI1HtKLFFQWl7ByBdm8nnORn7c52CuOK4zfTTzo4g0EEosUTB22rd8nrOR+8/rzYUD4vtiTRGRSNN5mQhbV1DEPe8spmtmEyUVEWmQ1GKJoNWbC3nwvSWUlFXw0LDvjagWEWkQlFgiZNz0b/nd+PkAjDy+C/06tohxRCIisaHEEgH/nLqK295YwPGHZXLDaYfRJ6t5rEMSEYkZJZYD4O68OWctt72xgIObpzHq4v6an15EGjwllgNw3djZvDMvj25t0nn+FwOUVEREUGKpsU07inknuJnkn37aR0lFRCSg4cY19OcPlgFw3cmHKqmIiFSixFIDHy1Zzz+mrmJI74M4vF2zWIcjIhJXdCpsPxSVlvPPqat48L0ltG2Wyt1De8U6JBGRuKPEEqYtO0u49PnpzF29lT5ZzXng/CNplZ4a67BEROKOEksYXpm+mr98nENewS7uPqcXFw86JNYhiYjELSWWaqzfVsR9kxbz5py1HNY2nWdHHM3xmqNeRKRadSaxmNlg4DEgEXjG3R+I5vttLyrljD9/ytbCUkYe34WbzuhOkuZSERHZpzqRWMwsEfgrcBqQC0w3s4nuviga77diww5+/sxXbC0s5ZlLsjm1Z9tovI2ISL1UV76CDwBy3H2Fu5cALwNDo/FGJWUV3Pr6fPIKinjiwqOUVERE9lOdaLEA7YHVldZzgYGRfpPVmwu59LlpLN+wk1uH9ODHfQ6O9FuIiNR7dSWxWBVl/p0NzEYCIwE6dqzZBFsHNU/jkFZNuOXMw9VSERGpobqSWHKBDpXWs4C1lTdw91HAKIDs7OzvJJ1wJScmMPrSo2sao4iIUHf6WKYD3cyss5mlAMOBiTGOSUREqlAnWizuXmZm1wGTCQ03Hu3uC2McloiIVKFOJBYAd58ETIp1HCIiUr26cipMRETqCCUWERGJKCUWERGJKCUWERGJKCUWERGJKHOv0bWEcc3MNgCrarBra2BjhMOpS1R/1V/1b7haA03c/YDnBqmXiaWmzGyGu2fHOo5YUf1Vf9Vf9Y/EsXQqTEREIkqJRUREIkqJ5btGxTqAGFP9GzbVv2GLWP3VxyIiIhGlFouIiESUEkvAzAab2VIzyzGzm2MdT6SY2WgzyzezBZXKWprZFDNbFjy3CMrNzB4PPoN5Ztav0j4jgu2XmdmIWNRlf5lZBzP72MwWm9lCM/t1UN5Q6p9mZtPMbG5Q/zuD8s5m9lVQl3HBVBSYWWqwnhO83qnSsW4Jypea2RmxqVHNmFmimc02s7eD9QZTfzNbaWbzzWyOmc0IyqL/++/uDf5B6Fb8y4EuQAowF+gZ67giVLfjgX7AgkplfwRuDpZvBh4MlocA7xKasXMQ8FVQ3hJYETy3CJZbxLpuYdS9HdAvWG4KfA30bED1NyA9WE4Gvgrq9QowPCh/Grg6WL4GeDpYHg6MC5Z7Bn8TqUDn4G8lMdb124/P4QbgJeDtYL3B1B9YCbTeoyzqv/9qsYQMAHLcfYW7lwAvA0NjHFNEuPunwOY9iocCY4LlMcA5lcpf8JCpQIaZtQPOAKa4+2Z33wJMAQZHP/oD4+557j4rWN4OLAba03Dq7+6+I1hNDh4OnAy8FpTvWf/dn8trwClmZkH5y+5e7O7fADmE/mbinpllAWcBzwTrRgOq/15E/fdfiSWkPbC60npuUFZftXX3PAj98wXaBOV7+xzq/OcTnNY4itC39gZT/+A00Bwgn9A/hOXAVncvCzapXJf/1DN4vQBoRR2uP/Bn4CagIlhvRcOqvwPvm9lMMxsZlEX997/OTPQVZVZFWUMcLre3z6FOfz5mlg6MB653922hL6FVb1pFWZ2uv7uXA33NLAN4HTi8qs2C53pVfzP7EZDv7jPN7MTdxVVsWi/rHzjW3deaWRtgipktqWbbiNVfLZaQXKBDpfUsYG2MYqkN64MmLsFzflC+t8+hzn4+ZpZMKKm86O4TguIGU//d3H0r8Amhc+cZZrb7S2XluvynnsHrzQmdRq2r9T8WONvMVhI6vX0yoRZMQ6k/7r42eM4n9MViALXw+6/EEjId6BaMFkkh1HE3McYxRdNEYPfIjhHAm5XKLwlGhwwCCoKm8mTgdDNrEYwgOT0oi2vB+fFngcXu/killxpK/TODlgpm1gg4lVA/08fAT4LN9qz/7s/lJ8BHHuq9nQgMD0ZNdQa6AdNqpxY15+63uHuWu3ci9Df9kbv/nAZSfzNrYmZNdy8T+r1dQG38/sd61EK8PAiNiPia0Dno38c6ngjWayyQB5QS+uZxOaHzxh8Cy4LnlsG2Bvw1+AzmA9mVjvMLQp2WOcBlsa5XmHU/jlCTfR4wJ3gMaUD1PxKYHdR/AfB/QXkXQv8Yc4BXgdSgPC1Yzwle71LpWL8PPpelwJmxrlsNPosT+e+osAZR/6Cec4PHwt3/12rj919X3ouISETpVJiIiESUEouIiESUEouIiESUEouIiESUEouIiESUEouIiESUEouIiESUEouIiETU/wN27Qp7MuEzqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a98b1be80>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine prediction arrays into a single list\n",
    "predictions = c(preds_train, preds_test)\n",
    "responses = c(Y_train, Y_test)\n",
    "\n",
    "# as a holding size, we'll take predicted return divided by return variance\n",
    "# this is mean-variance optimization with a single asset\n",
    "vols = vol_df.loc[K:n,'vol']\n",
    "position_size = predictions / vols ** 2\n",
    "\n",
    "# TODO: Calculate pnl. Pnl in each time period is holding * realized return.\n",
    "performance = position_size * responses\n",
    "\n",
    "# plot simulated performance\n",
    "plt.plot(np.cumsum(performance))\n",
    "plt.ylabel('Simulated Performance')\n",
    "plt.axvline(x=breakpoint, c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simulated returns accumulate throughout the training period, but they are absolutely flat in the testing period. The model has no predictive power whatsoever in the out-of-sample period.\n",
    "\n",
    "Can you think of a few reasons our simulation of performance is unrealistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Answer the above question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you need a little assistance, check out the [solution](overfitting_exercise_solution.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
